{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------reading data\n",
      "Here is an example of the first image in training set...\n",
      "Training dataset shape: (60000, 28, 28)\n",
      "Testing dataset shape: (10000, 28, 28)\n",
      "----------------------------------------creating model\n",
      "<keras.models.Sequential object at 0x000000001C213BE0>\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def mlp_model(input_shape, num_classes=10):\n",
    "    \"\"\"\n",
    "    Multilayer perceptron model. Not a very deep network.\n",
    "    :param input_dim:\n",
    "    :param num_classes:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=input_shape, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2)) # Dropout helps protect the model from memorizing or \"overfitting\" the training data\n",
    "    model.add(Dense(512, input_shape=input_shape, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2)) \n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(512, input_shape=(784,)))\n",
    "#     model.add(Activation('relu')) # An \"activation\" is just a non-linear function applied to the output\n",
    "#                                   # of the layer above. Here, with a \"rectified linear unit\",\n",
    "#                                   # we clamp all values below 0 to 0.\n",
    "\n",
    "#     model.add(Dropout(0.2))   \n",
    "#     model.add(Dense(512))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(10))\n",
    "#     model.add(Activation('softmax')) # This special \"softmax\" activation among other things,\n",
    "#                                      # ensures the output is a valid probaility distribution, that is\n",
    "#                                      # that its values are all non-negative and sum to 1.\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('-'*40+'reading data')\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#     im1 = np.array(x_train[:1]).reshape(28, 28)\n",
    "#     cv2.imwrite('mnist_sample1.jpg', im1)\n",
    "\n",
    "    print('Here is an example of the first image in training set...')\n",
    "    cv2.imshow('mnist_sample1.jpg', im1)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # fix random seed for reproducibility\n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # flatten 28*28 images to a 784 vector for each image\n",
    "    num_pixels = x_train.shape[1] * x_train.shape[2]\n",
    "    X_train = x_train.reshape(x_train.shape[0], num_pixels).astype('float32')/255.\n",
    "    X_test = x_test.reshape(x_test.shape[0], num_pixels).astype('float32')/255.\n",
    "    print('Training dataset shape: {}'.format(x_train.shape))\n",
    "    print('Testing dataset shape: {}'.format(x_test.shape))\n",
    "    Y_train = np_utils.to_categorical(y_train, 10)\n",
    "    Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "    print('-'*40+'creating model')\n",
    "    model = mlp_model((784, ), num_classes=10)\n",
    "    print(model)\n",
    "    model.fit(X_train, Y_train, epochs=10, batch_size=32)\n",
    "    score = model.evaluate(X_test, Y_test)\n",
    "    print(\"Our Test Accuracy was {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
